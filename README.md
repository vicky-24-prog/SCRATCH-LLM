# SCRATCH-LLM ğŸ§   
**AI Model Router with Benchmarking, Compare Mode & Observability Dashboard**

An end-to-end AI system that intelligently classifies user queries, routes them to the most suitable free LLM, evaluates response quality using an LLM-as-a-Judge, and provides full observability via analytics and comparison dashboards.

> This project is built to demonstrate **real AI engineering practices** â€” routing, evaluation, benchmarking, and system observability â€” not just prompt demos.

---

## ğŸš€ What This Project Does

- ğŸ” **Classifies queries** into task types (Coding, Math, Factual QA, Summarization, Creative) using **Gemini Flash**
- âš¡ **Routes queries** to the optimal free LLM via **OpenRouter**
- ğŸ§ª **Benchmarks routing accuracy** on a labeled dataset
- â­ **Evaluates answer quality** using Gemini as an automated judge (LLM-as-Judge)
- ğŸ” **Compare Mode** to visually compare multiple LLM outputs side-by-side
- ğŸ“Š **Analytics Dashboard** for latency, quality, routing distribution, and usage insights
- ğŸ—„ï¸ **SQLite logging** for full system observability

---

## ğŸ§  System Architecture (High Level)
```
User Query
â”‚
â–¼
Gemini Flash (Classifier)
â”‚ â†’ Task Type + Confidence
â–¼
Routing Logic
â”‚
â–¼
OpenRouter (free models)
â”‚
â–¼
Answer + Latency + Tokens
â”‚
â–¼
SQLite Logs
â”‚
â”œâ”€ Benchmarking
â”œâ”€ Quality Scoring (Gemini Judge)
â””â”€ Streamlit Dashboards
```
---

## ğŸ§© Tech Stack

- **Python**
- **Gemini 2.0 Flash** (classification + quality scoring)
- **OpenRouter** (free LLM inference)
- **Streamlit** (UI + dashboards)
- **SQLite** (logging & analytics)
- **Pandas** (analysis)

---

## ğŸ“ Project Structure
```
SCRATCH-LLM/
â”‚
â”œâ”€â”€ app.py # Main Streamlit app (Router UI)
â”œâ”€â”€ test_router.py # Smoke test for routing
â”‚
â”œâ”€â”€ router/
â”‚ â”œâ”€â”€ classifier.py # Gemini-based task classifier
â”‚ â”œâ”€â”€ selector.py # Routing logic
â”‚ â”œâ”€â”€ caller.py # OpenRouter API calls
â”‚ â””â”€â”€ pipeline.py # End-to-end routing pipeline
â”‚
â”œâ”€â”€ benchmark/
â”‚ â”œâ”€â”€ queries.json # 50 labeled benchmark queries
â”‚ â”œâ”€â”€ run_benchmark.py # Routing accuracy evaluation
â”‚ â””â”€â”€ evaluate.py # Gemini-as-judge quality scoring
â”‚
â”œâ”€â”€ pages/
â”‚ â”œâ”€â”€ compare.py # Compare Mode (side-by-side LLM outputs)
â”‚ â””â”€â”€ analytics.py # Observability dashboard
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ router.db # SQLite database (ignored by git)
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore

```

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/vicky-24-prog/SCRATCH-LLM.git
cd SCRATCH-LLM
python -m venv venv
venv\Scripts\activate
python -m venv venv
venv\Scripts\activate
GEMINI_KEY=your_gemini_api_key
OPENROUTER_KEY=your_openrouter_api_key
